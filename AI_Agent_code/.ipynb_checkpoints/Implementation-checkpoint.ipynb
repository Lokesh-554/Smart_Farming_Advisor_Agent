{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63c21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"space_id\": \"68a5eeaa-b793-4819-ae3a-c4b340d0b088\", \n",
    "}\n",
    "\n",
    "\n",
    "def gen_ai_service(context, params = params, **custom):\n",
    "    # import dependencies\n",
    "    from langchain_ibm import ChatWatsonx\n",
    "    from ibm_watsonx_ai import APIClient\n",
    "    from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
    "    from langchain_core.messages import AIMessage, HumanMessage\n",
    "    from langgraph.checkpoint.memory import MemorySaver\n",
    "    from langgraph.prebuilt import create_react_agent\n",
    "    import json\n",
    "    import requests\n",
    "\n",
    "    model = \"ibm/granite-3-3-8b-instruct\"\n",
    "    \n",
    "    service_url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "    # Get credentials token\n",
    "    credentials = {\n",
    "        \"url\": service_url,\n",
    "        \"token\": context.generate_token()\n",
    "    }\n",
    "\n",
    "    # Setup client\n",
    "    client = APIClient(credentials)\n",
    "    space_id = params.get(\"space_id\")\n",
    "    client.set.default_space(space_id)\n",
    "\n",
    "\n",
    "    def decrypt_tool_secrets(secrets):\n",
    "        url = \"https://api.dataplatform.cloud.ibm.com\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f'Bearer {context.generate_token()}'\n",
    "        }\n",
    "    \n",
    "        body = {\n",
    "            \"secrets\": secrets,\n",
    "            \"space_id\": space_id\n",
    "        }\n",
    "    \n",
    "        response = requests.post(f'{url}/wx/v1-beta/utility_agent_tools/secret/decrypt', headers=headers, json=body)\n",
    "    \n",
    "        return response.json().get(\"secrets\")\n",
    "    \n",
    "    encrypted_secrets = [\n",
    "        \"gcm-agent-tools-qHi31me0EfjVZVuGAnau05GBdpyvCVyV:4KghE14CF5EtFUxlcA6V+w==;8c5H+XcMqylHgAz12QxHrA==:wLZoVsFH6dFNbIbhdY0Ne8YAnWL7o6Lm2uLRu7sEFpzv7AbPraFCUp8=\"\n",
    "    ]\n",
    "    decrypted_secrets = decrypt_tool_secrets(encrypted_secrets)\n",
    "    \n",
    "    TavilySearch_apiKey = decrypted_secrets[0]\n",
    "    \n",
    "\n",
    "    def create_chat_model(watsonx_client):\n",
    "        parameters = {\n",
    "            \"frequency_penalty\": 0,\n",
    "            \"max_tokens\": 2000,\n",
    "            \"presence_penalty\": 0,\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 1\n",
    "        }\n",
    "\n",
    "        chat_model = ChatWatsonx(\n",
    "            model_id=model,\n",
    "            url=service_url,\n",
    "            space_id=space_id,\n",
    "            params=parameters,\n",
    "            watsonx_client=watsonx_client,\n",
    "        )\n",
    "        return chat_model\n",
    "    \n",
    "    \n",
    "    def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n",
    "        from langchain_core.tools import StructuredTool\n",
    "        utility_agent_tool = Toolkit(\n",
    "            api_client=api_client\n",
    "        ).get_tool(tool_name)\n",
    "    \n",
    "        tool_description = utility_agent_tool.get(\"description\")\n",
    "    \n",
    "        if (kwargs.get(\"tool_description\")):\n",
    "            tool_description = kwargs.get(\"tool_description\")\n",
    "        elif (utility_agent_tool.get(\"agent_description\")):\n",
    "            tool_description = utility_agent_tool.get(\"agent_description\")\n",
    "        \n",
    "        tool_schema = utility_agent_tool.get(\"input_schema\")\n",
    "        if (tool_schema == None):\n",
    "            tool_schema = {\n",
    "                \"type\": \"object\",\n",
    "                \"additionalProperties\": False,\n",
    "                \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "                \"properties\": {\n",
    "                    \"input\": {\n",
    "                        \"description\": \"input for the tool\",\n",
    "                        \"type\": \"string\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        def run_tool(**tool_input):\n",
    "            query = tool_input\n",
    "            if (utility_agent_tool.get(\"input_schema\") == None):\n",
    "                query = tool_input.get(\"input\")\n",
    "    \n",
    "            results = utility_agent_tool.run(\n",
    "                input=query,\n",
    "                config=params\n",
    "            )\n",
    "            \n",
    "            return results.get(\"output\")\n",
    "        \n",
    "        return StructuredTool(\n",
    "            name=tool_name,\n",
    "            description = tool_description,\n",
    "            func=run_tool,\n",
    "            args_schema=tool_schema\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n",
    "        from langchain_core.tools import StructuredTool\n",
    "        import ast\n",
    "    \n",
    "        def call_tool(**kwargs):\n",
    "            tree = ast.parse(tool_code, mode=\"exec\")\n",
    "            custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n",
    "            function_name = custom_tool_functions[0].name\n",
    "            compiled_code = compile(tree, 'custom_tool', 'exec')\n",
    "            namespace = tool_params if tool_params else {}\n",
    "            exec(compiled_code, namespace)\n",
    "            return namespace[function_name](**kwargs)\n",
    "            \n",
    "        tool = StructuredTool(\n",
    "            name=tool_name,\n",
    "            description = tool_description,\n",
    "            func=call_tool,\n",
    "            args_schema=tool_schema\n",
    "        )\n",
    "        return tool\n",
    "    \n",
    "    def create_custom_tools():\n",
    "        custom_tools = []\n",
    "    \n",
    "\n",
    "    def create_tools(inner_client, context):\n",
    "        tools = []\n",
    "        \n",
    "        config = None\n",
    "        tools.append(create_utility_agent_tool(\"GoogleSearch\", config, inner_client))\n",
    "        config = {\n",
    "        }\n",
    "        tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, inner_client))\n",
    "        config = {\n",
    "            \"maxResults\": 5\n",
    "        }\n",
    "        tools.append(create_utility_agent_tool(\"Wikipedia\", config, inner_client))\n",
    "        config = {\n",
    "        }\n",
    "        tools.append(create_utility_agent_tool(\"WebCrawler\", config, inner_client))\n",
    "        config = {\n",
    "        }\n",
    "        tools.append(create_utility_agent_tool(\"Weather\", config, inner_client))\n",
    "        config = {\n",
    "            \"maxResults\": 10,\n",
    "            \"apiKey\": TavilySearch_apiKey\n",
    "        }\n",
    "        tools.append(create_utility_agent_tool(\"TavilySearch\", config, inner_client))\n",
    "        return tools\n",
    "    \n",
    "    def create_agent(model, tools, messages):\n",
    "        memory = MemorySaver()\n",
    "        instructions = \"\"\"# Notes\n",
    "- When a tool is required to answer the user's query, respond only with <|tool_call|> followed by a JSON list of tools used.\n",
    "- If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\n",
    "You are a Smart Farming Advisor AI agent that provides real-time, localized agricultural guidance to small-scale farmers in India.\n",
    "\n",
    "Your knowledge comes from the uploaded documents and datasets in your Knowledge Base, which include:\n",
    "- Crop recommendations and yield data\n",
    "- Mandi (market) commodity prices\n",
    "- Pest and disease control methods\n",
    "- Soil guidelines and fertilizer recommendations\n",
    "- National and regional farming guidelines\n",
    "\n",
    "Your objectives:\n",
    "1. Answer farmer questions accurately using the Knowledge Base first.\n",
    "2. If a question requires current weather or market rates, call the connected tools (e.g., weather API, mandi price API) when available.\n",
    "3. Always respond in the farmer’s preferred language (Hindi, Telugu, Tamil, Kannada, or English), matching the language used in the query.\n",
    "4. Give answers in a simple, easy-to-follow format with clear steps or bullet points.\n",
    "5. Include reasoning or source context from the Knowledge Base so the farmer understands why you recommend something.\n",
    "\n",
    "You can help farmers with:\n",
    "- Best crops to plant this season based on soil, weather, and state.\n",
    "- Current mandi prices for crops in specific markets.\n",
    "- Pest and disease identification and safe, cost-effective control methods.\n",
    "- Soil preparation and fertilizer advice based on soil type.\n",
    "- Weather-based planning for sowing, irrigation, and harvesting.\n",
    "\n",
    "Guidelines:\n",
    "- Keep answers short, relevant, and practical.\n",
    "- If the query is unclear, politely ask for more details (location, crop, season).\n",
    "- If the requested information is not found in the Knowledge Base or via tools, reply: \n",
    "  \\\"I do not have that information right now. Please check with your local agriculture office or mandi board for the latest details.\\\"\n",
    "- Always use respectful and supportive language to build farmer trust.\n",
    "\n",
    "Examples of queries you can answer:\n",
    "- \\\"What crop should I grow in Kharif season in Karnataka with red sandy soil?\\\"\n",
    "- \\\"आज गुंटूर में टमाटर का मंडी भाव क्या है?\\\"\n",
    "- \\\"How to control fruit borer in tomatoes?\\\"\n",
    "- \\\"What fertilizer is best for black cotton soil for cotton crop?\\\"\n",
    "\"\"\"\n",
    "        for message in messages:\n",
    "            if message[\"role\"] == \"system\":\n",
    "                instructions += message[\"content\"]\n",
    "        graph = create_react_agent(model, tools=tools, checkpointer=memory, state_modifier=instructions)\n",
    "        return graph\n",
    "    \n",
    "    def convert_messages(messages):\n",
    "        converted_messages = []\n",
    "        for message in messages:\n",
    "            if (message[\"role\"] == \"user\"):\n",
    "                converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
    "            elif (message[\"role\"] == \"assistant\"):\n",
    "                converted_messages.append(AIMessage(content=message[\"content\"]))\n",
    "        return converted_messages\n",
    "\n",
    "    def generate(context):\n",
    "        payload = context.get_json()\n",
    "        messages = payload.get(\"messages\")\n",
    "        inner_credentials = {\n",
    "            \"url\": service_url,\n",
    "            \"token\": context.get_token()\n",
    "        }\n",
    "\n",
    "        inner_client = APIClient(inner_credentials)\n",
    "        model = create_chat_model(inner_client)\n",
    "        tools = create_tools(inner_client, context)\n",
    "        agent = create_agent(model, tools, messages)\n",
    "        \n",
    "        generated_response = agent.invoke(\n",
    "            { \"messages\": convert_messages(messages) },\n",
    "            { \"configurable\": { \"thread_id\": \"42\" } }\n",
    "        )\n",
    "\n",
    "        last_message = generated_response[\"messages\"][-1]\n",
    "        generated_response = last_message.content\n",
    "\n",
    "        execute_response = {\n",
    "            \"headers\": {\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            },\n",
    "            \"body\": {\n",
    "                \"choices\": [{\n",
    "                    \"index\": 0,\n",
    "                    \"message\": {\n",
    "                       \"role\": \"assistant\",\n",
    "                       \"content\": generated_response\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return execute_response\n",
    "\n",
    "    def generate_stream(context):\n",
    "        print(\"Generate stream\", flush=True)\n",
    "        payload = context.get_json()\n",
    "        headers = context.get_headers()\n",
    "        is_assistant = headers.get(\"X-Ai-Interface\") == \"assistant\"\n",
    "        messages = payload.get(\"messages\")\n",
    "        inner_credentials = {\n",
    "            \"url\": service_url,\n",
    "            \"token\": context.get_token()\n",
    "        }\n",
    "        inner_client = APIClient(inner_credentials)\n",
    "        model = create_chat_model(inner_client)\n",
    "        tools = create_tools(inner_client, context)\n",
    "        agent = create_agent(model, tools, messages)\n",
    "\n",
    "        response_stream = agent.stream(\n",
    "            { \"messages\": messages },\n",
    "            { \"configurable\": { \"thread_id\": \"42\" } },\n",
    "            stream_mode=[\"updates\", \"messages\"]\n",
    "        )\n",
    "\n",
    "        for chunk in response_stream:\n",
    "            chunk_type = chunk[0]\n",
    "            finish_reason = \"\"\n",
    "            usage = None\n",
    "            if (chunk_type == \"messages\"):\n",
    "                message_object = chunk[1][0]\n",
    "                if (message_object.type == \"AIMessageChunk\" and message_object.content != \"\"):\n",
    "                    message = {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": message_object.content\n",
    "                    }\n",
    "                else:\n",
    "                    continue\n",
    "            elif (chunk_type == \"updates\"):\n",
    "                update = chunk[1]\n",
    "                if (\"agent\" in update):\n",
    "                    agent = update[\"agent\"]\n",
    "                    agent_result = agent[\"messages\"][0]\n",
    "                    if (agent_result.additional_kwargs):\n",
    "                        kwargs = agent[\"messages\"][0].additional_kwargs\n",
    "                        tool_call = kwargs[\"tool_calls\"][0]\n",
    "                        if (is_assistant):\n",
    "                            message = {\n",
    "                                \"role\": \"assistant\",\n",
    "                                \"step_details\": {\n",
    "                                    \"type\": \"tool_calls\",\n",
    "                                    \"tool_calls\": [\n",
    "                                        {\n",
    "                                            \"id\": tool_call[\"id\"],\n",
    "                                            \"name\": tool_call[\"function\"][\"name\"],\n",
    "                                            \"args\": tool_call[\"function\"][\"arguments\"]\n",
    "                                        }\n",
    "                                    ] \n",
    "                                }\n",
    "                            }\n",
    "                        else:\n",
    "                            message = {\n",
    "                                \"role\": \"assistant\",\n",
    "                                \"tool_calls\": [\n",
    "                                    {\n",
    "                                        \"id\": tool_call[\"id\"],\n",
    "                                        \"type\": \"function\",\n",
    "                                        \"function\": {\n",
    "                                            \"name\": tool_call[\"function\"][\"name\"],\n",
    "                                            \"arguments\": tool_call[\"function\"][\"arguments\"]\n",
    "                                        }\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                    elif (agent_result.response_metadata):\n",
    "                        # Final update\n",
    "                        message = {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": agent_result.content\n",
    "                        }\n",
    "                        finish_reason = agent_result.response_metadata[\"finish_reason\"]\n",
    "                        if (finish_reason): \n",
    "                            message[\"content\"] = \"\"\n",
    "\n",
    "                        usage = {\n",
    "                            \"completion_tokens\": agent_result.usage_metadata[\"output_tokens\"],\n",
    "                            \"prompt_tokens\": agent_result.usage_metadata[\"input_tokens\"],\n",
    "                            \"total_tokens\": agent_result.usage_metadata[\"total_tokens\"]\n",
    "                        }\n",
    "                elif (\"tools\" in update):\n",
    "                    tools = update[\"tools\"]\n",
    "                    tool_result = tools[\"messages\"][0]\n",
    "                    if (is_assistant):\n",
    "                        message = {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"step_details\": {\n",
    "                                \"type\": \"tool_response\",\n",
    "                                \"id\": tool_result.id,\n",
    "                                \"tool_call_id\": tool_result.tool_call_id,\n",
    "                                \"name\": tool_result.name,\n",
    "                                \"content\": tool_result.content\n",
    "                            }\n",
    "                        }\n",
    "                    else:\n",
    "                        message = {\n",
    "                            \"role\": \"tool\",\n",
    "                            \"id\": tool_result.id,\n",
    "                            \"tool_call_id\": tool_result.tool_call_id,\n",
    "                            \"name\": tool_result.name,\n",
    "                            \"content\": tool_result.content\n",
    "                        }\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            chunk_response = {\n",
    "                \"choices\": [{\n",
    "                    \"index\": 0,\n",
    "                    \"delta\": message\n",
    "                }]\n",
    "            }\n",
    "            if (finish_reason):\n",
    "                chunk_response[\"choices\"][0][\"finish_reason\"] = finish_reason\n",
    "            if (usage):\n",
    "                chunk_response[\"usage\"] = usage\n",
    "            yield chunk_response\n",
    "\n",
    "    return generate, generate_stream\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
